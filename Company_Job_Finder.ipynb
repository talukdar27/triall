{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "83pOqr20AvWt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD1PwlK3OPsLE38mziLavR9ocMtDEYqPn4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ0J3US0IO1l",
        "outputId": "74b956b9-6182-4ec5-8e0b-26d5eeb98442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\ritama\\anaconda3\\lib\\site-packages (3.8.7)\n",
            "Requirement already satisfied: pdfplumber in c:\\users\\ritama\\anaconda3\\lib\\site-packages (0.11.7)\n",
            "Requirement already satisfied: python-docx in c:\\users\\ritama\\anaconda3\\lib\\site-packages (1.2.0)\n",
            "Requirement already satisfied: langchain in c:\\users\\ritama\\anaconda3\\lib\\site-packages (0.2.6)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\users\\ritama\\anaconda3\\lib\\site-packages (1.0.7)\n",
            "Requirement already satisfied: langgraph in c:\\users\\ritama\\anaconda3\\lib\\site-packages (0.4.5)\n",
            "Requirement already satisfied: pydantic in c:\\users\\ritama\\anaconda3\\lib\\site-packages (2.11.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (0.19.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber) (42.0.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (0.2.43)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.7.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pydantic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.136.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.31.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.25.8)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.6)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.63.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.21)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.62.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ritama\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy pdfplumber python-docx langchain langchain-google-genai langgraph pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ddt47uH63V",
        "outputId": "b7cdba10-3edc-43fa-e33f-4a7f4172c5d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     ---- ----------------------------------- 1.3/12.8 MB 6.1 MB/s eta 0:00:02\n",
            "     --------- ------------------------------ 2.9/12.8 MB 6.7 MB/s eta 0:00:02\n",
            "     ------------ --------------------------- 3.9/12.8 MB 6.0 MB/s eta 0:00:02\n",
            "     ------------------ --------------------- 6.0/12.8 MB 7.0 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 7.3/12.8 MB 6.9 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 8.7/12.8 MB 6.9 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 10.2/12.8 MB 6.9 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 11.0/12.8 MB 6.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 12.1/12.8 MB 6.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.8/12.8 MB 6.1 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rIdpiquB-duw"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import TypedDict, Annotated, List, Dict\n",
        "import operator\n",
        "import time\n",
        "import pdfplumber\n",
        "import docx\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from typing import Dict, List\n",
        "from pydantic import BaseModel\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
        "POLICY_FILE = \"/content/Company_Policies.txt\"\n",
        "\n",
        "class ParsedResume(BaseModel):\n",
        "    \"\"\"Schema for the data extracted from a resume.\"\"\"\n",
        "    name: str\n",
        "    email: str\n",
        "    mobile_number: str\n",
        "    skills: List[str]\n",
        "    education: str\n",
        "    work_experience_years: float\n",
        "    filename: str\n",
        "\n",
        "\n",
        "class SimulatedResumeParser:\n",
        "    def __init__(self, resume_path: str, skills_file: str = None, custom_regex: str = None):\n",
        "        self.resume_path = resume_path\n",
        "        self.__skills_file = skills_file\n",
        "        self.__custom_regex = custom_regex\n",
        "        self.__text = self.__extract_text(resume_path)\n",
        "\n",
        "        # Load spaCy NLP\n",
        "        self.__nlp = spacy.load(\"en_core_web_sm\")\n",
        "        self.__doc = self.__nlp(self.__text)\n",
        "        self.__matcher = Matcher(self.__nlp.vocab)\n",
        "\n",
        "        # Extract details\n",
        "        self.__details = self.__get_basic_details()\n",
        "\n",
        "    def __extract_text(self, resume_path: str) -> str:\n",
        "        \"\"\"Extract text from TXT, PDF, or DOCX files.\"\"\"\n",
        "        ext = os.path.splitext(resume_path)[1].lower()\n",
        "\n",
        "        if ext == \".pdf\":\n",
        "            text = \"\"\n",
        "            try:\n",
        "                with pdfplumber.open(resume_path) as pdf:\n",
        "                    for page in pdf.pages:\n",
        "                        text += page.extract_text() or \"\"\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading PDF {resume_path}: {e}\")\n",
        "                return \"\"\n",
        "\n",
        "        elif ext == \".docx\":\n",
        "            text = \"\"\n",
        "            try:\n",
        "                doc = docx.Document(resume_path)\n",
        "                for para in doc.paragraphs:\n",
        "                    text += para.text + \"\\n\"\n",
        "                return text\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading DOCX {resume_path}: {e}\")\n",
        "                return \"\"\n",
        "\n",
        "        else:  # fallback for plain text\n",
        "            try:\n",
        "                with open(resume_path, 'r', encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    return f.read()\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading text file {resume_path}: {e}\")\n",
        "                return \"\"\n",
        "\n",
        "    def __get_basic_details(self) -> Dict:\n",
        "        \"\"\"Extract details using spaCy NLP + regex (like original ResumeParser).\"\"\"\n",
        "        text = self.__text\n",
        "        doc = self.__doc\n",
        "        details = {}\n",
        "\n",
        "        name = None\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"PERSON\":\n",
        "                name = ent.text\n",
        "                break\n",
        "        details[\"name\"] = name if name else \"Unknown Candidate\"\n",
        "\n",
        "        email = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\", text)\n",
        "        details[\"email\"] = email.group(0) if email else \"N/A\"\n",
        "\n",
        "        mobile = re.search(self.__custom_regex or r\"(\\+?\\d[\\d\\-\\s]{8,}\\d)\", text)\n",
        "        details[\"mobile_number\"] = mobile.group(0) if mobile else \"N/A\"\n",
        "\n",
        "        skill_keywords = []\n",
        "        if self.__skills_file and os.path.exists(self.__skills_file):\n",
        "            with open(self.__skills_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                skill_keywords = [line.strip() for line in f if line.strip()]\n",
        "        else:\n",
        "            skill_keywords = [\"Python\", \"SQL\", \"Spark\", \"AWS\", \"Kubernetes\",\n",
        "                              \"SEO\", \"Marketing\", \"JavaScript\", \"React\", \"Node.js\"]\n",
        "\n",
        "        found_skills = [s for s in skill_keywords if re.search(r\"\\b\" + re.escape(s) + r\"\\b\", text, re.IGNORECASE)]\n",
        "        details[\"skills\"] = found_skills\n",
        "\n",
        "        edu_keywords = [\"B.S.\", \"B.Sc\", \"M.S.\", \"M.Sc\", \"PhD\", \"Bachelor\", \"Master\", \"MBA\", \"B.Tech\", \"M.Tech\"]\n",
        "        education = None\n",
        "        for token in doc:\n",
        "            for kw in edu_keywords:\n",
        "                if kw.lower() in token.text.lower():\n",
        "                    education = token.sent.text\n",
        "                    break\n",
        "        if not education:\n",
        "            education = \"Degree Placeholder\"\n",
        "        details[\"education\"] = education\n",
        "\n",
        "        years_exp = 0.0\n",
        "        exp_match = re.search(r\"(\\d+)\\s+years\", text, re.IGNORECASE)\n",
        "        if exp_match:\n",
        "            years_exp = float(exp_match.group(1))\n",
        "        else:\n",
        "            years_exp = 1.0\n",
        "        details[\"work_experience_years\"] = years_exp\n",
        "\n",
        "        details[\"filename\"] = os.path.basename(self.resume_path)\n",
        "        return details\n",
        "\n",
        "    def get_extracted_data(self) -> ParsedResume:\n",
        "        \"\"\"Return extracted resume data as a Pydantic model.\"\"\"\n",
        "        return ParsedResume(**self.__details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arif3BWEI8df",
        "outputId": "6801245c-4bc1-45bf-a652-e6781b7722f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ERROR] Skills file not found: content/Skills.txt\n",
            "[OK] Resume folder found: content/Resumes\n",
            "Files inside: ['Pratham_Thakkar.pdf', 'Praveen_kumar_T_resume.pdf', 'Vidit_Jain.pdf']\n",
            "\n",
            "🔹 Parsing file: content/Resumes\\Pratham_Thakkar.pdf\n",
            "\n",
            "🔹 Parsing file: content/Resumes\\Praveen_kumar_T_resume.pdf\n",
            "\n",
            "🔹 Parsing file: content/Resumes\\Vidit_Jain.pdf\n",
            "\n",
            "✅ Final extracted results:\n",
            "[{'education': 'Implementedrobustfeaturesincludinguserauthenticationand • '\n",
            "               'Rated1961(CandidateMaster,top200In-\\n'\n",
            "               'registration, post management, page creation, follower system, '\n",
            "               'and dia)onCodeforces(Handle:ppt1524)and\\n'\n",
            "               'moderatorprivileges,etc. 5staronCodechef(Handle:ppt1524)\\n'\n",
            "               '• Techstackused:ReactJS|ExpressJS|NodeJS|MongoDB|Nginx •',\n",
            "  'email': 'prathampthakkar@gmail.com',\n",
            "  'filename': 'Pratham_Thakkar.pdf',\n",
            "  'mobile_number': '+918849917720',\n",
            "  'name': 'batch',\n",
            "  'skills': ['Python', 'JavaScript'],\n",
            "  'work_experience_years': 1.0},\n",
            " {'education': 'Academic details\\nB.Tech from IIT Jodhpur(2015-2019).',\n",
            "  'email': 'praveenkumart236@gmail.com',\n",
            "  'filename': 'Praveen_kumar_T_resume.pdf',\n",
            "  'mobile_number': '8310618685',\n",
            "  'name': 'Png',\n",
            "  'skills': ['Python', 'AWS'],\n",
            "  'work_experience_years': 1.0},\n",
            " {'education': 'ACHIEVEMENTS\\n'\n",
            "               '● '\n",
            "               'Codeforces(fangahawk)-2113(Master),top1.5%Globally,top75inIndia.\\n',\n",
            "  'email': 'jain.vidit@students.iiit.ac.in',\n",
            "  'filename': 'Vidit_Jain.pdf',\n",
            "  'mobile_number': 'N/A',\n",
            "  'name': 'Suresh Purini',\n",
            "  'skills': ['Python', 'SQL', 'React'],\n",
            "  'work_experience_years': 1.0}]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pprint\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    resume_folder = \"content/Resumes\"\n",
        "    skills_file = \"content/Skills.txt\"\n",
        "\n",
        "    # 🔹 Check skills file\n",
        "    if os.path.exists(skills_file):\n",
        "        print(f\"[OK] Skills file found: {skills_file}\")\n",
        "        with open(skills_file, \"r\") as f:\n",
        "            print(\"Sample skills loaded:\", [line.strip() for line in f.readlines()[:5]])\n",
        "    else:\n",
        "        print(f\"[ERROR] Skills file not found: {skills_file}\")\n",
        "\n",
        "    # 🔹 Check resumes folder\n",
        "    if not os.path.exists(resume_folder):\n",
        "        print(f\"[ERROR] Resume folder not found: {resume_folder}\")\n",
        "    else:\n",
        "        print(f\"[OK] Resume folder found: {resume_folder}\")\n",
        "        print(\"Files inside:\", os.listdir(resume_folder))\n",
        "\n",
        "    results = []\n",
        "    for filename in os.listdir(resume_folder):\n",
        "        filepath = os.path.join(resume_folder, filename)\n",
        "\n",
        "        if not os.path.isfile(filepath):\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n🔹 Parsing file: {filepath}\")   # debug print\n",
        "        parser = SimulatedResumeParser(filepath, skills_file=skills_file)\n",
        "        extracted = parser.get_extracted_data()\n",
        "        results.append(extracted.dict())\n",
        "\n",
        "    print(\"\\n✅ Final extracted results:\")\n",
        "    pprint.pprint(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d2BDrSg8_sCY"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def generate_onboarding_plan(candidate_data: dict, role: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses an LLM to create a structured 30-60-90 day onboarding plan\n",
        "    based on the candidate's skills and the specific job role.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Create a detailed, actionable 30-60-90 day onboarding plan for the new hire:\n",
        "    - Name: {candidate_data.get('name')}\n",
        "    - Skills: {', '.join(candidate_data.get('skills', []))}\n",
        "    - Target Role: {role}\n",
        "\n",
        "    Structure the output clearly with the 30, 60, and 90-day milestones.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ORG1o1FU_s27"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def process_and_score_resume(resume_filepath: str, job_requirements: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parses a single resume file, extracts key details using the parser,\n",
        "    and then calculates a similarity score against the job_requirements using LLM.\n",
        "    \"\"\"\n",
        "    print(f\"  > Processing {os.path.basename(resume_filepath)}...\")\n",
        "\n",
        "    # 1. Use the simulated parser\n",
        "    parser = SimulatedResumeParser(resume_filepath)\n",
        "    parsed_data = parser.get_extracted_data().dict()\n",
        "\n",
        "    # 2. Use LLM to score the relevance\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional HR screener. Score the candidate's relevance for the job\n",
        "    based on their extracted skills and experience.\n",
        "\n",
        "    JOB REQUIREMENTS: {job_requirements}\n",
        "    CANDIDATE PROFILE:\n",
        "    - Skills: {', '.join(parsed_data['skills'])}\n",
        "    - Experience: {parsed_data['work_experience_years']} years.\n",
        "    - Education: {parsed_data['education']}\n",
        "\n",
        "    Provide ONLY a single float score between 0.0 (not relevant) and 1.0 (perfect fit)\n",
        "    in your response. Do not include any other text or explanation.\n",
        "    \"\"\"\n",
        "\n",
        "    score = 0.5 # Default score if LLM extraction fails\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        # Attempt to find the score float in the response content\n",
        "        score_match = re.search(r'(\\d\\.\\d+)', response.content.strip())\n",
        "        if score_match:\n",
        "            score = float(score_match.group(1))\n",
        "    except Exception as e:\n",
        "        print(f\"LLM scoring failed, using default: {e}\")\n",
        "\n",
        "    time.sleep(0.1) # Simulate complex operation time\n",
        "\n",
        "    return {\n",
        "        \"candidate_data\": parsed_data,\n",
        "        \"relevance_score\": score,\n",
        "        \"filename\": os.path.basename(resume_filepath)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Y1m5Vn9s_z08"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def retrieve_policy_answer(question: str, policy_file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Simulates a RAG tool by searching a local policy file for an answer.\n",
        "    \"\"\"\n",
        "    print(f\"  > Searching policy documents for: '{question}'\")\n",
        "\n",
        "    try:\n",
        "        with open(policy_file_path, 'r') as f:\n",
        "            policy_text = f.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: Policy documents ({policy_file_path}) were not found. Cannot answer policy questions.\"\n",
        "\n",
        "    # Use LLM to perform Q/A over the retrieved text (simulated RAG context)\n",
        "    prompt = f\"\"\"\n",
        "    Using ONLY the following policy text, answer the user's question concisely.\n",
        "    If the answer is not available in the text, state that.\n",
        "\n",
        "    POLICY TEXT:\n",
        "    ---\n",
        "    {policy_text}\n",
        "    ---\n",
        "\n",
        "    QUESTION: {question}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WLfrVlo7hjf"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    \"\"\"Represents the state of our multi-agent system.\"\"\"\n",
        "    input: str\n",
        "    chat_history: Annotated[List[HumanMessage], operator.add]\n",
        "    job_requirements: str\n",
        "    processed_resumes: List[dict]\n",
        "    best_candidate: dict\n",
        "    onboarding_plan: str\n",
        "    final_output: str\n",
        "    next_action: str\n",
        "    resume_directory: str\n",
        "    policy_file_path: str # Added policy file path to state\n",
        "\n",
        "\n",
        "class ManagerOrchestrator:\n",
        "    \"\"\"Directs the flow based on the user's request.\"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.tool_map = {\n",
        "            \"process_and_score_resume\": \"TalentScout\",\n",
        "            \"retrieve_policy_answer\": \"PolicyQA\",\n",
        "            \"generate_onboarding_plan\": \"Onboarder\"\n",
        "        }\n",
        "        self.llm = llm.bind_tools([process_and_score_resume, retrieve_policy_answer, generate_onboarding_plan])\n",
        "\n",
        "    def route_request(self, state: AgentState):\n",
        "        \"\"\"Routes the request to the appropriate agent.\"\"\"\n",
        "\n",
        "        if state.get('next_action') == \"ONBOARD_BEST_CANDIDATE\":\n",
        "            return {\"next_action\": \"Onboarder\"}\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are the Manager/Orchestrator. Determine the user's intent:\n",
        "        1. **RESUME SCREENING**: If the user asks to \"find the best candidate\" or \"screen resumes\" (delegate to TalentScout).\n",
        "        2. **POLICY QUESTION**: If the user asks about \"policy,\" \"vacation,\" \"leave,\" \"expense\" (delegate to PolicyQA).\n",
        "        3. **ONBOARDING**: If the user asks to \"create plan\" or \"onboard\" and a candidate is already selected (delegate to Onboarder).\n",
        "\n",
        "        Current Request: {state['input']}\n",
        "\n",
        "        Delegate the task by calling the appropriate tool. If the request does not clearly fit, just output a conversational response.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Use tool calling to force a decision\n",
        "            response = self.llm.invoke(prompt)\n",
        "            tool_call = response.tool_calls[0]\n",
        "            tool_name = tool_call['name']\n",
        "\n",
        "            agent_role = self.tool_map.get(tool_name)\n",
        "            if agent_role:\n",
        "                print(f\"\\n[Orchestrator] ROUTING: {tool_name} -> {agent_role}\")\n",
        "                return {\"next_action\": agent_role}\n",
        "\n",
        "        except Exception:\n",
        "            # If no tool call, assume conversational response is required\n",
        "            print(\"\\n[Orchestrator] ROUTING: Conversational Response/Fallback\")\n",
        "            return {\"final_output\": f\"I'm an HR automation system. I can screen resumes, answer policy questions, and create onboarding plans. Please specify what you need.\"}\n",
        "\n",
        "\n",
        "class TalentScout:\n",
        "    \"\"\"Agent for parsing, scoring, and selecting the best resume.\"\"\"\n",
        "\n",
        "    def run_screening(self, state: AgentState):\n",
        "        \"\"\"Scans the directory and runs the scoring tool for all files.\"\"\"\n",
        "        print(f\"\\n[TalentScout] Starting screening in directory: {state['resume_directory']}\")\n",
        "\n",
        "        # Filter files to only include common resume types\n",
        "        resume_files = [os.path.join(state['resume_directory'], f)\n",
        "                        for f in os.listdir(state['resume_directory'])\n",
        "                        if f.lower().endswith(('.txt', '.pdf', '.docx'))]\n",
        "\n",
        "        if not resume_files:\n",
        "            return {\"final_output\": f\"Error: No .txt, .pdf, or .docx files found in the specified directory: {state['resume_directory']}\"}\n",
        "\n",
        "        all_results = []\n",
        "        for file_path in resume_files:\n",
        "            try:\n",
        "                # Invoke the tool for each resume\n",
        "                result = process_and_score_resume.invoke({\n",
        "                    \"resume_filepath\": file_path,\n",
        "                    \"job_requirements\": state['job_requirements']\n",
        "                })\n",
        "                all_results.append(result)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "        # Select the best candidate\n",
        "        best_candidate = max(all_results, key=lambda x: x['relevance_score'])\n",
        "\n",
        "        output_message = (\n",
        "            f\"Screening complete! **{len(all_results)}** resumes processed.\\n\\n\"\n",
        "            f\"**Top Candidate:** {best_candidate['candidate_data']['name']}\\n\"\n",
        "            f\"**File:** {best_candidate['filename']}\\n\"\n",
        "            f\"**Relevance Score:** {best_candidate['relevance_score']:.2f}/1.00\\n\"\n",
        "            f\"**Action:** The best candidate has been selected. Do you want to proceed with **Onboarding Plan** creation?\"\n",
        "        )\n",
        "        # Select the best candidate\n",
        "        # best_candidate = max(all_results, key=lambda x: x['relevance_score'])\n",
        "\n",
        "        # # Sort all results by score (highest first)\n",
        "        # sorted_results = sorted(all_results, key=lambda x: x['relevance_score'], reverse=True)\n",
        "\n",
        "        # # Build output showing all candidates\n",
        "        # output_message = f\"Screening complete! **{len(all_results)}** resumes processed.\\n\\n\"\n",
        "        # output_message += \"**All Candidates (sorted by score):**\\n\\n\"\n",
        "\n",
        "        # for idx, result in enumerate(sorted_results, 1):\n",
        "        #     output_message += (\n",
        "        #         f\"{idx}. **{result['candidate_data']['name']}**\\n\"\n",
        "        #         f\"   - File: {result['filename']}\\n\"\n",
        "        #         f\"   - Score: {result['relevance_score']:.2f}/1.00\\n\"\n",
        "        #         f\"   - Skills: {', '.join(result['candidate_data']['skills'])}\\n\"\n",
        "        #         f\"   - Experience: {result['candidate_data']['work_experience_years']} years\\n\\n\"\n",
        "        #     )\n",
        "\n",
        "        # output_message += f\"\\n**Top Candidate Selected:** {best_candidate['candidate_data']['name']}\\n\"\n",
        "        # output_message += \"**Action:** Do you want to proceed with **Onboarding Plan** creation?\"\n",
        "\n",
        "        return {\n",
        "            \"processed_resumes\": all_results,\n",
        "            \"best_candidate\": best_candidate['candidate_data'],\n",
        "            \"final_output\": output_message,\n",
        "            \"next_action\": \"SCREENING_COMPLETE\"\n",
        "        }\n",
        "\n",
        "class Onboarder:\n",
        "    \"\"\"Generate onboarding plan using LLM\"\"\"\n",
        "    @staticmethod\n",
        "    def create_plan(state: AgentState):\n",
        "        candidate = state['best_candidate']\n",
        "        if not candidate:\n",
        "            return {\"final_output\": \"No best candidate selected!\", \"next_action\": \"\"}\n",
        "\n",
        "        # Read company policies text\n",
        "        try:\n",
        "            with open(state['policy_file_path'], \"r\", encoding=\"utf-8\") as f:\n",
        "                policies_text = f.read()\n",
        "        except Exception as e:\n",
        "            return {\"final_output\": f\"Error reading policy file: {e}\", \"next_action\": \"\"}\n",
        "\n",
        "        # LLM prompt\n",
        "        prompt = f\"\"\"\n",
        "You are an HR automation assistant. Generate a comprehensive onboarding plan\n",
        "for a new employee based on the following information.\n",
        "\n",
        "Candidate Details:\n",
        "- Name: {candidate['name']}\n",
        "- Email: {candidate['email']}\n",
        "- Skills: {', '.join(candidate['skills'])}\n",
        "- Education: {candidate['education']}\n",
        "- Work Experience (years): {candidate['work_experience_years']}\n",
        "\n",
        "Job Requirements:\n",
        "{state['job_requirements']}\n",
        "\n",
        "Company Policies (summarized or relevant sections):\n",
        "{policies_text[:3000]}  # use first 3000 chars to avoid hitting token limits\n",
        "\n",
        "Requirements:\n",
        "- Provide a step-by-step onboarding plan.\n",
        "- Include tasks such as document submission, orientation, setup, team introduction, and first project assignment.\n",
        "- Reference company policies where relevant.\n",
        "- Keep it professional and clear.\n",
        "\n",
        "Output the onboarding plan in readable steps.\n",
        "\"\"\"\n",
        "\n",
        "        # Call the LLM\n",
        "        try:\n",
        "            from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "            llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3)\n",
        "            response = llm.invoke(prompt)\n",
        "            plan_content = response.content # Access the content attribute\n",
        "        except Exception as e:\n",
        "            return {\"final_output\": f\"Error generating onboarding plan with LLM: {e}\", \"next_action\": \"\"}\n",
        "\n",
        "        final_message = f\"--- ✅ Onboarding Plan Generated ✅ ---\\n{plan_content}\"\n",
        "\n",
        "        return {\n",
        "            \"onboarding_plan\": plan_content,\n",
        "            \"final_output\": final_message,\n",
        "            \"next_action\": \"PolicyQA\"\n",
        "        }\n",
        "\n",
        "\n",
        "class PolicyQA:\n",
        "    \"\"\"Agent for answering policy questions using RAG.\"\"\"\n",
        "\n",
        "    def answer_question(self, state: AgentState):\n",
        "        \"\"\"Invokes the RAG tool to get the policy answer.\"\"\"\n",
        "        print(f\"\\n[PolicyQA] Answering question...\")\n",
        "\n",
        "        answer = retrieve_policy_answer.invoke({\"question\": state['input'], \"policy_file_path\": state['policy_file_path']}) # Pass policy file path\n",
        "\n",
        "        final_message = f\"--- 📄 **Policy Answer** 📄 ---\\n{answer}\"\n",
        "\n",
        "        return {\n",
        "            \"final_output\": final_message,\n",
        "            \"next_action\": \"QA_COMPLETE\"\n",
        "        }\n",
        "\n",
        "def execute_tool_call(state: AgentState):\n",
        "    \"\"\"Executes the specific agent logic determined by the Manager.\"\"\"\n",
        "    action = state['next_action']\n",
        "\n",
        "    if action == \"TalentScout\":\n",
        "        return TalentScout().run_screening(state)\n",
        "    elif action == \"PolicyQA\":\n",
        "        return PolicyQA().answer_question(state)\n",
        "    elif action == \"Onboarder\":\n",
        "        return Onboarder().create_plan(state)\n",
        "\n",
        "    return {\"final_output\": f\"Error: Unknown tool or missing logic for action: {action}\"}\n",
        "\n",
        "\n",
        "def build_app():\n",
        "    manager = ManagerOrchestrator(llm)\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    workflow.add_node(\"Manager\", manager.route_request)\n",
        "    workflow.add_node(\"ExecuteTool\", execute_tool_call)\n",
        "\n",
        "    workflow.set_entry_point(\"Manager\")\n",
        "    workflow.add_edge(\"Manager\", \"ExecuteTool\")\n",
        "\n",
        "    def decide_next_step(state: AgentState):\n",
        "        \"\"\"Conditional edge to route based on the ExecuteTool result.\"\"\"\n",
        "        action = state['next_action']\n",
        "\n",
        "        if action == \"SCREENING_COMPLETE\":\n",
        "            return \"Manager\"\n",
        "        elif action == \"QA_COMPLETE\" or action == \"ONBOARDING_COMPLETE\":\n",
        "            return END\n",
        "        else:\n",
        "            return \"Manager\"\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"ExecuteTool\",\n",
        "        decide_next_step,\n",
        "        {\"Manager\": \"Manager\", END: END}\n",
        "    )\n",
        "\n",
        "    return workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "z0KQR4yqUDH0"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def execute_tool_call(state: AgentState):\n",
        "    \"\"\"Executes the specific agent logic based on user selection.\"\"\"\n",
        "    action = state['next_action']\n",
        "\n",
        "    if action == \"TalentScout\":\n",
        "        output = TalentScout().run_screening(state)\n",
        "        state.update(output)\n",
        "        print(\"\\n\" + state['final_output'])\n",
        "    elif action == \"Onboarder\":\n",
        "        if not state.get(\"best_candidate\"):\n",
        "            print(\"\\nError: No TalentScout results available. Run TalentScout first.\")\n",
        "            return state\n",
        "        output = Onboarder().create_plan(state)\n",
        "        state.update(output)\n",
        "        print(\"\\n\" + state['final_output'])\n",
        "    elif action == \"PolicyQA\":\n",
        "        question = input(\"\\nEnter your policy question (or type 'exit' to go back): \")\n",
        "        if question.lower() != \"exit\":\n",
        "            state['input'] = question\n",
        "            output = PolicyQA().answer_question(state)\n",
        "            print(\"\\n\" + output['final_output'])\n",
        "            state.update(output)\n",
        "    else:\n",
        "        print(f\"\\nUnknown action: {action}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def build_user_driven_app():\n",
        "    \"\"\"Builds a workflow that executes a single tool based on user input and then ends.\"\"\"\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    workflow.add_node(\"ExecuteTool\", execute_tool_call)\n",
        "    workflow.set_entry_point(\"ExecuteTool\")\n",
        "    workflow.add_edge(\"ExecuteTool\", END) # Remove conditional edge, go directly to END\n",
        "\n",
        "    return workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcpmCvnUbgOm",
        "outputId": "1204188f-ba35-4970-e5fa-189c62a3e06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Available tools:\n",
            "1. TalentScout\n",
            "2. Onboarder\n",
            "3. PolicyQA\n",
            "4. Exit\n",
            "\n",
            "[TalentScout] Starting screening in directory: content/Resumes\n",
            "  > Processing Pratham_Thakkar.pdf...\n",
            "  > Processing Praveen_kumar_T_resume.pdf...\n",
            "  > Processing Vidit_Jain.pdf...\n",
            "\n",
            "Screening complete! **3** resumes processed.\n",
            "\n",
            "**All Candidates (sorted by score):**\n",
            "\n",
            "1. **Png**\n",
            "   - File: Praveen_kumar_T_resume.pdf\n",
            "   - Score: 0.95/1.00\n",
            "   - Skills: Python, AWS\n",
            "   - Experience: 1.0 years\n",
            "\n",
            "2. **Suresh Purini**\n",
            "   - File: Vidit_Jain.pdf\n",
            "   - Score: 0.95/1.00\n",
            "   - Skills: Python, SQL, React\n",
            "   - Experience: 1.0 years\n",
            "\n",
            "3. **batch**\n",
            "   - File: Pratham_Thakkar.pdf\n",
            "   - Score: 0.60/1.00\n",
            "   - Skills: Python, JavaScript\n",
            "   - Experience: 1.0 years\n",
            "\n",
            "\n",
            "**Top Candidate Selected:** Png\n",
            "**Action:** Do you want to proceed with **Onboarding Plan** creation?\n",
            "\n",
            "Available tools:\n",
            "1. TalentScout\n",
            "2. Onboarder\n",
            "3. PolicyQA\n",
            "4. Exit\n",
            "Exiting workflow.\n"
          ]
        }
      ],
      "source": [
        "# Initialize state\n",
        "state = AgentState(\n",
        "    input=\"\",\n",
        "    chat_history=[],\n",
        "    job_requirements=\"Entry level Data Engineer needing Python experience\",\n",
        "    processed_resumes=[],\n",
        "    best_candidate={},\n",
        "    onboarding_plan=\"\",\n",
        "    final_output=\"\",\n",
        "    next_action=\"ExecuteTool\",\n",
        "    resume_directory=\"content/Resumes\",\n",
        "    policy_file_path=\"content/Company_Policies.txt\"\n",
        ")\n",
        "\n",
        "# Build workflow\n",
        "workflow = build_user_driven_app()\n",
        "\n",
        "# Run interactively\n",
        "while True:\n",
        "    print(\"\\nAvailable tools:\\n1. TalentScout\\n2. Onboarder\\n3. PolicyQA\\n4. Exit\")\n",
        "    choice = input(\"Which tool do you want to run? \").strip().lower()\n",
        "\n",
        "    if choice in [\"exit\", \"4\"]:\n",
        "        print(\"Exiting workflow.\")\n",
        "        break\n",
        "    elif choice in [\"talentscout\", \"1\"]:\n",
        "        state['next_action'] = \"TalentScout\"\n",
        "    elif choice in [\"onboarder\", \"2\"]:\n",
        "        state['next_action'] = \"Onboarder\"\n",
        "    elif choice in [\"policyqa\", \"3\"]:\n",
        "        state['next_action'] = \"PolicyQA\"\n",
        "    else:\n",
        "        print(\"Invalid choice, please try again.\")\n",
        "        continue\n",
        "\n",
        "    state = workflow.invoke(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKFdzX2tbjAI",
        "outputId": "1e3744c4-5da0-4595-a353-b6c7d1f71d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Available tools:\n",
            "1. TalentScout\n",
            "2. Onboarder\n",
            "3. PolicyQA\n",
            "4. Exit\n",
            "Exiting workflow.\n"
          ]
        }
      ],
      "source": [
        "state = AgentState(\n",
        "    input=\"\",\n",
        "    chat_history=[],\n",
        "    job_requirements=\"\",\n",
        "    processed_resumes=[],\n",
        "    best_candidate={},\n",
        "    onboarding_plan=\"\",\n",
        "    final_output=\"\",\n",
        "    next_action=\"ExecuteTool\",\n",
        "    resume_directory=\"\",\n",
        "    policy_file_path=\"\"\n",
        ")\n",
        "\n",
        "while True:\n",
        "    policy_file = input(\"Enter the path to your company policies file: \").strip()\n",
        "    if policy_file and os.path.isfile(policy_file):\n",
        "        state['policy_file_path'] = policy_file\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid file path. Please try again.\")\n",
        "\n",
        "workflow = build_user_driven_app()\n",
        "\n",
        "while True:\n",
        "    print(\"\\nAvailable tools:\\n1. TalentScout\\n2. Onboarder\\n3. PolicyQA\\n4. Exit\")\n",
        "    choice = input(\"Which tool do you want to run? \").strip().lower()\n",
        "\n",
        "    if choice in [\"exit\", \"4\"]:\n",
        "        print(\"Exiting workflow.\")\n",
        "        break\n",
        "    elif choice in [\"talentscout\", \"1\"]:\n",
        "        while True:\n",
        "            resume_folder = input(\"Enter the path to your resume folder: \").strip()\n",
        "            if resume_folder and os.path.isdir(resume_folder):\n",
        "                state['resume_directory'] = resume_folder\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid folder path. Please try again.\")\n",
        "\n",
        "        state['job_requirements'] = input(\"Enter the Job Requirements: \").strip()\n",
        "        state['next_action'] = \"TalentScout\"\n",
        "\n",
        "    elif choice in [\"onboarder\", \"2\"]:\n",
        "        if not state.get(\"best_candidate\"):\n",
        "            print(\"No TalentScout results yet. Run TalentScout first.\")\n",
        "            continue\n",
        "        state['next_action'] = \"Onboarder\"\n",
        "\n",
        "    elif choice in [\"policyqa\", \"3\"]:\n",
        "        state['next_action'] = \"PolicyQA\"\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice, please try again.\")\n",
        "        continue\n",
        "\n",
        "    state = workflow.invoke(state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-04 22:36:52.823 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:52.824 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.148 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run c:\\Users\\Ritama\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
            "2025-10-04 22:36:53.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.155 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.157 Session state does not function when running a script without `streamlit run`\n",
            "2025-10-04 22:36:53.161 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.173 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.178 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.184 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.186 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.190 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.191 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.200 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.208 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.225 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.244 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.250 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-04 22:36:53.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
